{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb1772d",
   "metadata": {},
   "source": [
    "Analysis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b871de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5b9576b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "func_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "func_code_string",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "func_code_tokens",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "func_documentation_string",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "func_documentation_tokens",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "cffe00c7-6aa5-44ce-ae06-6cd1a8fc4811",
       "rows": [
        [
         "0",
         "train",
         "def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\n    \"\"\"\n    Trains a k-nearest neighbors classifier for face recognition.\n\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\n\n     (View in source code to see train_dir example tree structure)\n\n     Structure:\n        <train_dir>/\n        ├── <person1>/\n        │   ├── <somename1>.jpeg\n        │   ├── <somename2>.jpeg\n        │   ├── ...\n        ├── <person2>/\n        │   ├── <somename1>.jpeg\n        │   └── <somename2>.jpeg\n        └── ...\n\n    :param model_save_path: (optional) path to save model on disk\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\n    :param verbose: verbosity of training\n    :return: returns knn classifier that was trained on the given data.\n    \"\"\"\n    X = []\n    y = []\n\n    # Loop through each person in the training set\n    for class_dir in os.listdir(train_dir):\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\n            continue\n\n        # Loop through each training image for the current person\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\n            image = face_recognition.load_image_file(img_path)\n            face_bounding_boxes = face_recognition.face_locations(image)\n\n            if len(face_bounding_boxes) != 1:\n                # If there are no people (or too many people) in a training image, skip the image.\n                if verbose:\n                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn't find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\n            else:\n                # Add face encoding for current image to the training set\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\n                y.append(class_dir)\n\n    # Determine how many neighbors to use for weighting in the KNN classifier\n    if n_neighbors is None:\n        n_neighbors = int(round(math.sqrt(len(X))))\n        if verbose:\n            print(\"Chose n_neighbors automatically:\", n_neighbors)\n\n    # Create and train the KNN classifier\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\n    knn_clf.fit(X, y)\n\n    # Save the trained KNN classifier\n    if model_save_path is not None:\n        with open(model_save_path, 'wb') as f:\n            pickle.dump(knn_clf, f)\n\n    return knn_clf",
         "['def' 'train' '(' 'train_dir' ',' 'model_save_path' '=' 'None' ','\n 'n_neighbors' '=' 'None' ',' 'knn_algo' '=' \"'ball_tree'\" ',' 'verbose'\n '=' 'False' ')' ':' 'X' '=' '[' ']' 'y' '=' '[' ']'\n '# Loop through each person in the training set' 'for' 'class_dir' 'in'\n 'os' '.' 'listdir' '(' 'train_dir' ')' ':' 'if' 'not' 'os' '.' 'path' '.'\n 'isdir' '(' 'os' '.' 'path' '.' 'join' '(' 'train_dir' ',' 'class_dir'\n ')' ')' ':' 'continue'\n '# Loop through each training image for the current person' 'for'\n 'img_path' 'in' 'image_files_in_folder' '(' 'os' '.' 'path' '.' 'join'\n '(' 'train_dir' ',' 'class_dir' ')' ')' ':' 'image' '='\n 'face_recognition' '.' 'load_image_file' '(' 'img_path' ')'\n 'face_bounding_boxes' '=' 'face_recognition' '.' 'face_locations' '('\n 'image' ')' 'if' 'len' '(' 'face_bounding_boxes' ')' '!=' '1' ':'\n '# If there are no people (or too many people) in a training image, skip the image.'\n 'if' 'verbose' ':' 'print' '(' '\"Image {} not suitable for training: {}\"'\n '.' 'format' '(' 'img_path' ',' '\"Didn\\'t find a face\"' 'if' 'len' '('\n 'face_bounding_boxes' ')' '<' '1' 'else' '\"Found more than one face\"' ')'\n ')' 'else' ':'\n '# Add face encoding for current image to the training set' 'X' '.'\n 'append' '(' 'face_recognition' '.' 'face_encodings' '(' 'image' ','\n 'known_face_locations' '=' 'face_bounding_boxes' ')' '[' '0' ']' ')' 'y'\n '.' 'append' '(' 'class_dir' ')'\n '# Determine how many neighbors to use for weighting in the KNN classifier'\n 'if' 'n_neighbors' 'is' 'None' ':' 'n_neighbors' '=' 'int' '(' 'round'\n '(' 'math' '.' 'sqrt' '(' 'len' '(' 'X' ')' ')' ')' ')' 'if' 'verbose'\n ':' 'print' '(' '\"Chose n_neighbors automatically:\"' ',' 'n_neighbors'\n ')' '# Create and train the KNN classifier' 'knn_clf' '=' 'neighbors' '.'\n 'KNeighborsClassifier' '(' 'n_neighbors' '=' 'n_neighbors' ','\n 'algorithm' '=' 'knn_algo' ',' 'weights' '=' \"'distance'\" ')' 'knn_clf'\n '.' 'fit' '(' 'X' ',' 'y' ')' '# Save the trained KNN classifier' 'if'\n 'model_save_path' 'is' 'not' 'None' ':' 'with' 'open' '('\n 'model_save_path' ',' \"'wb'\" ')' 'as' 'f' ':' 'pickle' '.' 'dump' '('\n 'knn_clf' ',' 'f' ')' 'return' 'knn_clf']",
         "Trains a k-nearest neighbors classifier for face recognition.\n\n    :param train_dir: directory that contains a sub-directory for each known person, with its name.\n\n     (View in source code to see train_dir example tree structure)\n\n     Structure:\n        <train_dir>/\n        ├── <person1>/\n        │   ├── <somename1>.jpeg\n        │   ├── <somename2>.jpeg\n        │   ├── ...\n        ├── <person2>/\n        │   ├── <somename1>.jpeg\n        │   └── <somename2>.jpeg\n        └── ...\n\n    :param model_save_path: (optional) path to save model on disk\n    :param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\n    :param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\n    :param verbose: verbosity of training\n    :return: returns knn classifier that was trained on the given data.",
         "['Trains' 'a' 'k' '-' 'nearest' 'neighbors' 'classifier' 'for' 'face'\n 'recognition' '.']"
        ],
        [
         "1",
         "predict",
         "def predict(X_img_path, knn_clf=None, model_path=None, distance_threshold=0.6):\n    \"\"\"\n    Recognizes faces in given image using a trained KNN classifier\n\n    :param X_img_path: path to image to be recognized\n    :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified.\n    :param model_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf.\n    :param distance_threshold: (optional) distance threshold for face classification. the larger it is, the more chance\n           of mis-classifying an unknown person as a known one.\n    :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...].\n        For faces of unrecognized persons, the name 'unknown' will be returned.\n    \"\"\"\n    if not os.path.isfile(X_img_path) or os.path.splitext(X_img_path)[1][1:] not in ALLOWED_EXTENSIONS:\n        raise Exception(\"Invalid image path: {}\".format(X_img_path))\n\n    if knn_clf is None and model_path is None:\n        raise Exception(\"Must supply knn classifier either thourgh knn_clf or model_path\")\n\n    # Load a trained KNN model (if one was passed in)\n    if knn_clf is None:\n        with open(model_path, 'rb') as f:\n            knn_clf = pickle.load(f)\n\n    # Load image file and find face locations\n    X_img = face_recognition.load_image_file(X_img_path)\n    X_face_locations = face_recognition.face_locations(X_img)\n\n    # If no faces are found in the image, return an empty result.\n    if len(X_face_locations) == 0:\n        return []\n\n    # Find encodings for faces in the test iamge\n    faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_face_locations)\n\n    # Use the KNN model to find the best matches for the test face\n    closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1)\n    are_matches = [closest_distances[0][i][0] <= distance_threshold for i in range(len(X_face_locations))]\n\n    # Predict classes and remove classifications that aren't within the threshold\n    return [(pred, loc) if rec else (\"unknown\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_face_locations, are_matches)]",
         "['def' 'predict' '(' 'X_img_path' ',' 'knn_clf' '=' 'None' ','\n 'model_path' '=' 'None' ',' 'distance_threshold' '=' '0.6' ')' ':' 'if'\n 'not' 'os' '.' 'path' '.' 'isfile' '(' 'X_img_path' ')' 'or' 'os' '.'\n 'path' '.' 'splitext' '(' 'X_img_path' ')' '[' '1' ']' '[' '1' ':' ']'\n 'not' 'in' 'ALLOWED_EXTENSIONS' ':' 'raise' 'Exception' '('\n '\"Invalid image path: {}\"' '.' 'format' '(' 'X_img_path' ')' ')' 'if'\n 'knn_clf' 'is' 'None' 'and' 'model_path' 'is' 'None' ':' 'raise'\n 'Exception' '('\n '\"Must supply knn classifier either thourgh knn_clf or model_path\"' ')'\n '# Load a trained KNN model (if one was passed in)' 'if' 'knn_clf' 'is'\n 'None' ':' 'with' 'open' '(' 'model_path' ',' \"'rb'\" ')' 'as' 'f' ':'\n 'knn_clf' '=' 'pickle' '.' 'load' '(' 'f' ')'\n '# Load image file and find face locations' 'X_img' '='\n 'face_recognition' '.' 'load_image_file' '(' 'X_img_path' ')'\n 'X_face_locations' '=' 'face_recognition' '.' 'face_locations' '('\n 'X_img' ')'\n '# If no faces are found in the image, return an empty result.' 'if'\n 'len' '(' 'X_face_locations' ')' '==' '0' ':' 'return' '[' ']'\n '# Find encodings for faces in the test iamge' 'faces_encodings' '='\n 'face_recognition' '.' 'face_encodings' '(' 'X_img' ','\n 'known_face_locations' '=' 'X_face_locations' ')'\n '# Use the KNN model to find the best matches for the test face'\n 'closest_distances' '=' 'knn_clf' '.' 'kneighbors' '(' 'faces_encodings'\n ',' 'n_neighbors' '=' '1' ')' 'are_matches' '=' '[' 'closest_distances'\n '[' '0' ']' '[' 'i' ']' '[' '0' ']' '<=' 'distance_threshold' 'for' 'i'\n 'in' 'range' '(' 'len' '(' 'X_face_locations' ')' ')' ']'\n \"# Predict classes and remove classifications that aren't within the threshold\"\n 'return' '[' '(' 'pred' ',' 'loc' ')' 'if' 'rec' 'else' '(' '\"unknown\"'\n ',' 'loc' ')' 'for' 'pred' ',' 'loc' ',' 'rec' 'in' 'zip' '(' 'knn_clf'\n '.' 'predict' '(' 'faces_encodings' ')' ',' 'X_face_locations' ','\n 'are_matches' ')' ']']",
         "Recognizes faces in given image using a trained KNN classifier\n\n    :param X_img_path: path to image to be recognized\n    :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified.\n    :param model_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf.\n    :param distance_threshold: (optional) distance threshold for face classification. the larger it is, the more chance\n           of mis-classifying an unknown person as a known one.\n    :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...].\n        For faces of unrecognized persons, the name 'unknown' will be returned.",
         "['Recognizes' 'faces' 'in' 'given' 'image' 'using' 'a' 'trained' 'KNN'\n 'classifier']"
        ],
        [
         "2",
         "show_prediction_labels_on_image",
         "def show_prediction_labels_on_image(img_path, predictions):\n    \"\"\"\n    Shows the face recognition results visually.\n\n    :param img_path: path to image to be recognized\n    :param predictions: results of the predict function\n    :return:\n    \"\"\"\n    pil_image = Image.open(img_path).convert(\"RGB\")\n    draw = ImageDraw.Draw(pil_image)\n\n    for name, (top, right, bottom, left) in predictions:\n        # Draw a box around the face using the Pillow module\n        draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n\n        # There's a bug in Pillow where it blows up with non-UTF-8 text\n        # when using the default bitmap font\n        name = name.encode(\"UTF-8\")\n\n        # Draw a label with a name below the face\n        text_width, text_height = draw.textsize(name)\n        draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n        draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n\n    # Remove the drawing library from memory as per the Pillow docs\n    del draw\n\n    # Display the resulting image\n    pil_image.show()",
         "['def' 'show_prediction_labels_on_image' '(' 'img_path' ',' 'predictions'\n ')' ':' 'pil_image' '=' 'Image' '.' 'open' '(' 'img_path' ')' '.'\n 'convert' '(' '\"RGB\"' ')' 'draw' '=' 'ImageDraw' '.' 'Draw' '('\n 'pil_image' ')' 'for' 'name' ',' '(' 'top' ',' 'right' ',' 'bottom' ','\n 'left' ')' 'in' 'predictions' ':'\n '# Draw a box around the face using the Pillow module' 'draw' '.'\n 'rectangle' '(' '(' '(' 'left' ',' 'top' ')' ',' '(' 'right' ',' 'bottom'\n ')' ')' ',' 'outline' '=' '(' '0' ',' '0' ',' '255' ')' ')'\n \"# There's a bug in Pillow where it blows up with non-UTF-8 text\"\n '# when using the default bitmap font' 'name' '=' 'name' '.' 'encode' '('\n '\"UTF-8\"' ')' '# Draw a label with a name below the face' 'text_width'\n ',' 'text_height' '=' 'draw' '.' 'textsize' '(' 'name' ')' 'draw' '.'\n 'rectangle' '(' '(' '(' 'left' ',' 'bottom' '-' 'text_height' '-' '10'\n ')' ',' '(' 'right' ',' 'bottom' ')' ')' ',' 'fill' '=' '(' '0' ',' '0'\n ',' '255' ')' ',' 'outline' '=' '(' '0' ',' '0' ',' '255' ')' ')' 'draw'\n '.' 'text' '(' '(' 'left' '+' '6' ',' 'bottom' '-' 'text_height' '-' '5'\n ')' ',' 'name' ',' 'fill' '=' '(' '255' ',' '255' ',' '255' ',' '255' ')'\n ')' '# Remove the drawing library from memory as per the Pillow docs'\n 'del' 'draw' '# Display the resulting image' 'pil_image' '.' 'show' '('\n ')']",
         "Shows the face recognition results visually.\n\n    :param img_path: path to image to be recognized\n    :param predictions: results of the predict function\n    :return:",
         "['Shows' 'the' 'face' 'recognition' 'results' 'visually' '.']"
        ],
        [
         "3",
         "_rect_to_css",
         "def _rect_to_css(rect):\n    \"\"\"\n    Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) order\n\n    :param rect: a dlib 'rect' object\n    :return: a plain tuple representation of the rect in (top, right, bottom, left) order\n    \"\"\"\n    return rect.top(), rect.right(), rect.bottom(), rect.left()",
         "['def' '_rect_to_css' '(' 'rect' ')' ':' 'return' 'rect' '.' 'top' '(' ')'\n ',' 'rect' '.' 'right' '(' ')' ',' 'rect' '.' 'bottom' '(' ')' ',' 'rect'\n '.' 'left' '(' ')']",
         "Convert a dlib 'rect' object to a plain tuple in (top, right, bottom, left) order\n\n    :param rect: a dlib 'rect' object\n    :return: a plain tuple representation of the rect in (top, right, bottom, left) order",
         "['Convert' 'a' 'dlib' 'rect' 'object' 'to' 'a' 'plain' 'tuple' 'in' '('\n 'top' 'right' 'bottom' 'left' ')' 'order']"
        ],
        [
         "4",
         "_trim_css_to_bounds",
         "def _trim_css_to_bounds(css, image_shape):\n    \"\"\"\n    Make sure a tuple in (top, right, bottom, left) order is within the bounds of the image.\n\n    :param css:  plain tuple representation of the rect in (top, right, bottom, left) order\n    :param image_shape: numpy shape of the image array\n    :return: a trimmed plain tuple representation of the rect in (top, right, bottom, left) order\n    \"\"\"\n    return max(css[0], 0), min(css[1], image_shape[1]), min(css[2], image_shape[0]), max(css[3], 0)",
         "['def' '_trim_css_to_bounds' '(' 'css' ',' 'image_shape' ')' ':' 'return'\n 'max' '(' 'css' '[' '0' ']' ',' '0' ')' ',' 'min' '(' 'css' '[' '1' ']'\n ',' 'image_shape' '[' '1' ']' ')' ',' 'min' '(' 'css' '[' '2' ']' ','\n 'image_shape' '[' '0' ']' ')' ',' 'max' '(' 'css' '[' '3' ']' ',' '0' ')']",
         "Make sure a tuple in (top, right, bottom, left) order is within the bounds of the image.\n\n    :param css:  plain tuple representation of the rect in (top, right, bottom, left) order\n    :param image_shape: numpy shape of the image array\n    :return: a trimmed plain tuple representation of the rect in (top, right, bottom, left) order",
         "['Make' 'sure' 'a' 'tuple' 'in' '(' 'top' 'right' 'bottom' 'left' ')'\n 'order' 'is' 'within' 'the' 'bounds' 'of' 'the' 'image' '.']"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>func_name</th>\n",
       "      <th>func_code_string</th>\n",
       "      <th>func_code_tokens</th>\n",
       "      <th>func_documentation_string</th>\n",
       "      <th>func_documentation_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>def train(train_dir, model_save_path=None, n_n...</td>\n",
       "      <td>[def, train, (, train_dir, ,, model_save_path,...</td>\n",
       "      <td>Trains a k-nearest neighbors classifier for fa...</td>\n",
       "      <td>[Trains, a, k, -, nearest, neighbors, classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>predict</td>\n",
       "      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n",
       "      <td>[def, predict, (, X_img_path, ,, knn_clf, =, N...</td>\n",
       "      <td>Recognizes faces in given image using a traine...</td>\n",
       "      <td>[Recognizes, faces, in, given, image, using, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>show_prediction_labels_on_image</td>\n",
       "      <td>def show_prediction_labels_on_image(img_path, ...</td>\n",
       "      <td>[def, show_prediction_labels_on_image, (, img_...</td>\n",
       "      <td>Shows the face recognition results visually.\\n...</td>\n",
       "      <td>[Shows, the, face, recognition, results, visua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_rect_to_css</td>\n",
       "      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n",
       "      <td>[def, _rect_to_css, (, rect, ), :, return, rec...</td>\n",
       "      <td>Convert a dlib 'rect' object to a plain tuple ...</td>\n",
       "      <td>[Convert, a, dlib, rect, object, to, a, plain,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_trim_css_to_bounds</td>\n",
       "      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n",
       "      <td>[def, _trim_css_to_bounds, (, css, ,, image_sh...</td>\n",
       "      <td>Make sure a tuple in (top, right, bottom, left...</td>\n",
       "      <td>[Make, sure, a, tuple, in, (, top, right, bott...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         func_name  \\\n",
       "0                            train   \n",
       "1                          predict   \n",
       "2  show_prediction_labels_on_image   \n",
       "3                     _rect_to_css   \n",
       "4              _trim_css_to_bounds   \n",
       "\n",
       "                                    func_code_string  \\\n",
       "0  def train(train_dir, model_save_path=None, n_n...   \n",
       "1  def predict(X_img_path, knn_clf=None, model_pa...   \n",
       "2  def show_prediction_labels_on_image(img_path, ...   \n",
       "3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n",
       "4  def _trim_css_to_bounds(css, image_shape):\\n  ...   \n",
       "\n",
       "                                    func_code_tokens  \\\n",
       "0  [def, train, (, train_dir, ,, model_save_path,...   \n",
       "1  [def, predict, (, X_img_path, ,, knn_clf, =, N...   \n",
       "2  [def, show_prediction_labels_on_image, (, img_...   \n",
       "3  [def, _rect_to_css, (, rect, ), :, return, rec...   \n",
       "4  [def, _trim_css_to_bounds, (, css, ,, image_sh...   \n",
       "\n",
       "                           func_documentation_string  \\\n",
       "0  Trains a k-nearest neighbors classifier for fa...   \n",
       "1  Recognizes faces in given image using a traine...   \n",
       "2  Shows the face recognition results visually.\\n...   \n",
       "3  Convert a dlib 'rect' object to a plain tuple ...   \n",
       "4  Make sure a tuple in (top, right, bottom, left...   \n",
       "\n",
       "                           func_documentation_tokens  \n",
       "0  [Trains, a, k, -, nearest, neighbors, classifi...  \n",
       "1  [Recognizes, faces, in, given, image, using, a...  \n",
       "2  [Shows, the, face, recognition, results, visua...  \n",
       "3  [Convert, a, dlib, rect, object, to, a, plain,...  \n",
       "4  [Make, sure, a, tuple, in, (, top, right, bott...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset and convert to dataframe\n",
    "ds = load_dataset(\"code_search_net\", \"python\", trust_remote_code=True)\n",
    "df = ds['train'].to_pandas()\n",
    "\n",
    "# Retrieve necessary data series.\n",
    "df = df[['func_name', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'language']]\n",
    "\n",
    "# Only retrieve code written in Python.\n",
    "df = df.loc[df['language'] == 'python'].drop('language', axis=1)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d07345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 412178, 'test': 22176, 'validation': 23107}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of data in each set\n",
    "ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "30bef545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "func_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "func_code_string",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "func_code_tokens",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "func_documentation_string",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "func_documentation_tokens",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "func_code_tokens_len",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "func_documentation_tokens_len",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ffe83372-8fe5-476a-b3c0-03077f1c5440",
       "rows": [
        [
         "10978",
         "WechatSogouAPI.__hosting_wechat_img",
         "def __hosting_wechat_img(self, content_info, hosting_callback):\n        \"\"\"将微信明细中图片托管到云端，同时将html页面中的对应图片替换\n\n        Parameters\n        ----------\n        content_info : dict 微信文章明细字典\n            {\n                'content_img_list': [], # 从微信文章解析出的原始图片列表\n                'content_html': '', # 从微信文章解析出文章的内容\n            }\n        hosting_callback : callable\n            托管回调函数，传入单个图片链接，返回托管后的图片链接\n\n        Returns\n        -------\n        dict\n            {\n                'content_img_list': '', # 托管后的图片列表\n                'content_html': '',  # 图片链接为托管后的图片链接内容\n            }\n        \"\"\"\n        assert callable(hosting_callback)\n\n        content_img_list = content_info.pop(\"content_img_list\")\n        content_html = content_info.pop(\"content_html\")\n        for idx, img_url in enumerate(content_img_list):\n            hosting_img_url = hosting_callback(img_url)\n            if not hosting_img_url:\n                # todo 定义标准异常\n                raise Exception()\n            content_img_list[idx] = hosting_img_url\n            content_html = content_html.replace(img_url, hosting_img_url)\n\n        return dict(content_img_list=content_img_list, content_html=content_html)",
         "['def' '__hosting_wechat_img' '(' 'self' ',' 'content_info' ','\n 'hosting_callback' ')' ':' 'assert' 'callable' '(' 'hosting_callback' ')'\n 'content_img_list' '=' 'content_info' '.' 'pop' '(' '\"content_img_list\"'\n ')' 'content_html' '=' 'content_info' '.' 'pop' '(' '\"content_html\"' ')'\n 'for' 'idx' ',' 'img_url' 'in' 'enumerate' '(' 'content_img_list' ')' ':'\n 'hosting_img_url' '=' 'hosting_callback' '(' 'img_url' ')' 'if' 'not'\n 'hosting_img_url' ':' '# todo 定义标准异常' 'raise' 'Exception' '(' ')'\n 'content_img_list' '[' 'idx' ']' '=' 'hosting_img_url' 'content_html' '='\n 'content_html' '.' 'replace' '(' 'img_url' ',' 'hosting_img_url' ')'\n 'return' 'dict' '(' 'content_img_list' '=' 'content_img_list' ','\n 'content_html' '=' 'content_html' ')']",
         "将微信明细中图片托管到云端，同时将html页面中的对应图片替换\n\n        Parameters\n        ----------\n        content_info : dict 微信文章明细字典\n            {\n                'content_img_list': [], # 从微信文章解析出的原始图片列表\n                'content_html': '', # 从微信文章解析出文章的内容\n            }\n        hosting_callback : callable\n            托管回调函数，传入单个图片链接，返回托管后的图片链接\n\n        Returns\n        -------\n        dict\n            {\n                'content_img_list': '', # 托管后的图片列表\n                'content_html': '',  # 图片链接为托管后的图片链接内容\n            }",
         "['将微信明细中图片托管到云端，同时将html页面中的对应图片替换']",
         "83",
         "1"
        ],
        [
         "10984",
         "WechatSogouAPI.get_article_content",
         "def get_article_content(self, url, del_qqmusic=True, del_mpvoice=True, unlock_callback=None,\n                            identify_image_callback=None, hosting_callback=None, raw=False):\n        \"\"\"获取文章原文，避免临时链接失效\n\n        Parameters\n        ----------\n        url : str or unicode\n            原文链接，临时链接\n        raw : bool\n            True: 返回原始html\n            False: 返回处理后的html\n        del_qqmusic: bool\n            True:微信原文中有插入的qq音乐，则删除\n            False:微信源文中有插入的qq音乐，则保留\n        del_mpvoice: bool\n            True:微信原文中有插入的语音消息，则删除\n            False:微信源文中有插入的语音消息，则保留\n        unlock_callback : callable\n            处理 文章明细 的时候出现验证码的函数，参见 unlock_callback_example\n        identify_image_callback : callable\n            处理 文章明细 的时候处理验证码函数，输入验证码二进制数据，输出文字，参见 identify_image_callback_example\n        hosting_callback: callable\n            将微信采集的文章托管到7牛或者阿里云回调函数，输入微信图片源地址，返回托管后地址\n\n        Returns\n        -------\n        content_html\n            原文内容\n        content_img_list\n            文章中图片列表\n\n        Raises\n        ------\n        WechatSogouRequestsException\n        \"\"\"\n\n        resp = self.__get_by_unlock(url,\n                                    unlock_platform=self.__unlock_wechat,\n                                    unlock_callback=unlock_callback,\n                                    identify_image_callback=identify_image_callback)\n\n        resp.encoding = 'utf-8'\n        if '链接已过期' in resp.text:\n            raise WechatSogouException('get_article_content 链接 [{}] 已过期'.format(url))\n        if raw:\n            return resp.text\n        content_info = WechatSogouStructuring.get_article_detail(resp.text, del_qqmusic=del_qqmusic,\n                                                                 del_voice=del_mpvoice)\n        if hosting_callback:\n            content_info = self.__hosting_wechat_img(content_info, hosting_callback)\n        return content_info",
         "['def' 'get_article_content' '(' 'self' ',' 'url' ',' 'del_qqmusic' '='\n 'True' ',' 'del_mpvoice' '=' 'True' ',' 'unlock_callback' '=' 'None' ','\n 'identify_image_callback' '=' 'None' ',' 'hosting_callback' '=' 'None'\n ',' 'raw' '=' 'False' ')' ':' 'resp' '=' 'self' '.' '__get_by_unlock' '('\n 'url' ',' 'unlock_platform' '=' 'self' '.' '__unlock_wechat' ','\n 'unlock_callback' '=' 'unlock_callback' ',' 'identify_image_callback' '='\n 'identify_image_callback' ')' 'resp' '.' 'encoding' '=' \"'utf-8'\" 'if'\n \"'链接已过期' in resp.t\" 'xt' '' '' '' '' 'raise' 'WechatSogouException' '('\n \"'get_article_content 链接 [{}] 已过期'.format(ur\" 'l' '))' '' '' '' '' 'if'\n 'raw' ':' 'return' 'resp' '.' 'text' 'content_info' '='\n 'WechatSogouStructuring' '.' 'get_article_detail' '(' 'resp' '.' 'text'\n ',' 'del_qqmusic' '=' 'del_qqmusic' ',' 'del_voice' '=' 'del_mpvoice' ')'\n 'if' 'hosting_callback' ':' 'content_info' '=' 'self' '.'\n '__hosting_wechat_img' '(' 'content_info' ',' 'hosting_callback' ')'\n 'return' 'content_info']",
         "获取文章原文，避免临时链接失效\n\n        Parameters\n        ----------\n        url : str or unicode\n            原文链接，临时链接\n        raw : bool\n            True: 返回原始html\n            False: 返回处理后的html\n        del_qqmusic: bool\n            True:微信原文中有插入的qq音乐，则删除\n            False:微信源文中有插入的qq音乐，则保留\n        del_mpvoice: bool\n            True:微信原文中有插入的语音消息，则删除\n            False:微信源文中有插入的语音消息，则保留\n        unlock_callback : callable\n            处理 文章明细 的时候出现验证码的函数，参见 unlock_callback_example\n        identify_image_callback : callable\n            处理 文章明细 的时候处理验证码函数，输入验证码二进制数据，输出文字，参见 identify_image_callback_example\n        hosting_callback: callable\n            将微信采集的文章托管到7牛或者阿里云回调函数，输入微信图片源地址，返回托管后地址\n\n        Returns\n        -------\n        content_html\n            原文内容\n        content_img_list\n            文章中图片列表\n\n        Raises\n        ------\n        WechatSogouRequestsException",
         "['获取文章原文，避免临时链接失效']",
         "116",
         "1"
        ],
        [
         "10985",
         "WechatSogouAPI.get_sugg",
         "def get_sugg(self, keyword):\n        \"\"\"获取微信搜狗搜索关键词联想\n\n        Parameters\n        ----------\n        keyword : str or unicode\n            关键词\n\n        Returns\n        -------\n        list[str]\n            联想关键词列表\n\n        Raises\n        ------\n        WechatSogouRequestsException\n        \"\"\"\n        url = 'http://w.sugg.sogou.com/sugg/ajaj_json.jsp?key={}&type=wxpub&pr=web'.format(\n            quote(keyword.encode('utf-8')))\n        r = requests.get(url)\n        if not r.ok:\n            raise WechatSogouRequestsException('get_sugg', r)\n\n        sugg = re.findall(u'\\[\"' + keyword + '\",(.*?),\\[\"', r.text)[0]\n        return json.loads(sugg)",
         "['def' 'get_sugg' '(' 'self' ',' 'keyword' ')' ':' 'url' '='\n \"'http://w.sugg.sogou.com/sugg/ajaj_json.jsp?key={}&type=wxpub&pr=web'\"\n '.' 'format' '(' 'quote' '(' 'keyword' '.' 'encode' '(' \"'utf-8'\" ')' ')'\n ')' 'r' '=' 'requests' '.' 'get' '(' 'url' ')' 'if' 'not' 'r' '.' 'ok'\n ':' 'raise' 'WechatSogouRequestsException' '(' \"'get_sugg'\" ',' 'r' ')'\n 'sugg' '=' 're' '.' 'findall' '(' 'u\\'\\\\[\"\\'' '+' 'keyword' '+'\n '\\'\",(.*?),\\\\[\"\\'' ',' 'r' '.' 'text' ')' '[' '0' ']' 'return' 'json' '.'\n 'loads' '(' 'sugg' ')']",
         "获取微信搜狗搜索关键词联想\n\n        Parameters\n        ----------\n        keyword : str or unicode\n            关键词\n\n        Returns\n        -------\n        list[str]\n            联想关键词列表\n\n        Raises\n        ------\n        WechatSogouRequestsException",
         "['获取微信搜狗搜索关键词联想']",
         "71",
         "1"
        ],
        [
         "10986",
         "unlock_sogou_callback_example",
         "def unlock_sogou_callback_example(url, req, resp, img, identify_image_callback):\n    \"\"\"手动打码解锁\n\n    Parameters\n    ----------\n    url : str or unicode\n        验证码页面 之前的 url\n    req : requests.sessions.Session\n        requests.Session() 供调用解锁\n    resp : requests.models.Response\n        requests 访问页面返回的，已经跳转了\n    img : bytes\n        验证码图片二进制数据\n    identify_image_callback : callable\n        处理验证码函数，输入验证码二进制数据，输出文字，参见 identify_image_callback_example\n\n    Returns\n    -------\n    dict\n        {\n            'code': '',\n            'msg': '',\n        }\n    \"\"\"\n    # no use resp\n    url_quote = url.split('weixin.sogou.com/')[-1]\n    unlock_url = 'http://weixin.sogou.com/antispider/thank.php'\n    data = {\n        'c': identify_image_callback(img),\n        'r': '%2F' + url_quote,\n        'v': 5\n    }\n    headers = {\n        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n        'Referer': 'http://weixin.sogou.com/antispider/?from=%2f' + url_quote\n    }\n    r_unlock = req.post(unlock_url, data, headers=headers)\n    r_unlock.encoding = 'utf-8'\n    if not r_unlock.ok:\n        raise WechatSogouVcodeOcrException(\n            'unlock[{}] failed: {}'.format(unlock_url, r_unlock.text, r_unlock.status_code))\n\n    return r_unlock.json()",
         "['def' 'unlock_sogou_callback_example' '(' 'url' ',' 'req' ',' 'resp' ','\n 'img' ',' 'identify_image_callback' ')' ':' '# no use resp' 'url_quote'\n '=' 'url' '.' 'split' '(' \"'weixin.sogou.com/'\" ')' '[' '-' '1' ']'\n 'unlock_url' '=' \"'http://weixin.sogou.com/antispider/thank.php'\" 'data'\n '=' '{' \"'c'\" ':' 'identify_image_callback' '(' 'img' ')' ',' \"'r'\" ':'\n \"'%2F'\" '+' 'url_quote' ',' \"'v'\" ':' '5' '}' 'headers' '=' '{'\n \"'Content-Type'\" ':' \"'application/x-www-form-urlencoded; charset=UTF-8'\"\n ',' \"'Referer'\" ':' \"'http://weixin.sogou.com/antispider/?from=%2f'\" '+'\n 'url_quote' '}' 'r_unlock' '=' 'req' '.' 'post' '(' 'unlock_url' ','\n 'data' ',' 'headers' '=' 'headers' ')' 'r_unlock' '.' 'encoding' '='\n \"'utf-8'\" 'if' 'not' 'r_unlock' '.' 'ok' ':' 'raise'\n 'WechatSogouVcodeOcrException' '(' \"'unlock[{}] failed: {}'\" '.' 'format'\n '(' 'unlock_url' ',' 'r_unlock' '.' 'text' ',' 'r_unlock' '.'\n 'status_code' ')' ')' 'return' 'r_unlock' '.' 'json' '(' ')']",
         "手动打码解锁\n\n    Parameters\n    ----------\n    url : str or unicode\n        验证码页面 之前的 url\n    req : requests.sessions.Session\n        requests.Session() 供调用解锁\n    resp : requests.models.Response\n        requests 访问页面返回的，已经跳转了\n    img : bytes\n        验证码图片二进制数据\n    identify_image_callback : callable\n        处理验证码函数，输入验证码二进制数据，输出文字，参见 identify_image_callback_example\n\n    Returns\n    -------\n    dict\n        {\n            'code': '',\n            'msg': '',\n        }",
         "['手动打码解锁']",
         "112",
         "1"
        ],
        [
         "10987",
         "unlock_weixin_callback_example",
         "def unlock_weixin_callback_example(url, req, resp, img, identify_image_callback):\n    \"\"\"手动打码解锁\n\n    Parameters\n    ----------\n    url : str or unicode\n        验证码页面 之前的 url\n    req : requests.sessions.Session\n        requests.Session() 供调用解锁\n    resp : requests.models.Response\n        requests 访问页面返回的，已经跳转了\n    img : bytes\n        验证码图片二进制数据\n    identify_image_callback : callable\n        处理验证码函数，输入验证码二进制数据，输出文字，参见 identify_image_callback_example\n\n    Returns\n    -------\n    dict\n        {\n            'ret': '',\n            'errmsg': '',\n            'cookie_count': '',\n        }\n    \"\"\"\n    # no use resp\n\n    unlock_url = 'https://mp.weixin.qq.com/mp/verifycode'\n    data = {\n        'cert': time.time() * 1000,\n        'input': identify_image_callback(img)\n    }\n    headers = {\n        'Host': 'mp.weixin.qq.com',\n        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n        'Referer': url\n    }\n    r_unlock = req.post(unlock_url, data, headers=headers)\n    if not r_unlock.ok:\n        raise WechatSogouVcodeOcrException(\n            'unlock[{}] failed: {}[{}]'.format(unlock_url, r_unlock.text, r_unlock.status_code))\n\n    return r_unlock.json()",
         "['def' 'unlock_weixin_callback_example' '(' 'url' ',' 'req' ',' 'resp' ','\n 'img' ',' 'identify_image_callback' ')' ':' '# no use resp' 'unlock_url'\n '=' \"'https://mp.weixin.qq.com/mp/verifycode'\" 'data' '=' '{' \"'cert'\"\n ':' 'time' '.' 'time' '(' ')' '*' '1000' ',' \"'input'\" ':'\n 'identify_image_callback' '(' 'img' ')' '}' 'headers' '=' '{' \"'Host'\"\n ':' \"'mp.weixin.qq.com'\" ',' \"'Content-Type'\" ':'\n \"'application/x-www-form-urlencoded; charset=UTF-8'\" ',' \"'Referer'\" ':'\n 'url' '}' 'r_unlock' '=' 'req' '.' 'post' '(' 'unlock_url' ',' 'data' ','\n 'headers' '=' 'headers' ')' 'if' 'not' 'r_unlock' '.' 'ok' ':' 'raise'\n 'WechatSogouVcodeOcrException' '(' \"'unlock[{}] failed: {}[{}]'\" '.'\n 'format' '(' 'unlock_url' ',' 'r_unlock' '.' 'text' ',' 'r_unlock' '.'\n 'status_code' ')' ')' 'return' 'r_unlock' '.' 'json' '(' ')']",
         "手动打码解锁\n\n    Parameters\n    ----------\n    url : str or unicode\n        验证码页面 之前的 url\n    req : requests.sessions.Session\n        requests.Session() 供调用解锁\n    resp : requests.models.Response\n        requests 访问页面返回的，已经跳转了\n    img : bytes\n        验证码图片二进制数据\n    identify_image_callback : callable\n        处理验证码函数，输入验证码二进制数据，输出文字，参见 identify_image_callback_example\n\n    Returns\n    -------\n    dict\n        {\n            'ret': '',\n            'errmsg': '',\n            'cookie_count': '',\n        }",
         "['手动打码解锁']",
         "97",
         "1"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>func_name</th>\n",
       "      <th>func_code_string</th>\n",
       "      <th>func_code_tokens</th>\n",
       "      <th>func_documentation_string</th>\n",
       "      <th>func_documentation_tokens</th>\n",
       "      <th>func_code_tokens_len</th>\n",
       "      <th>func_documentation_tokens_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>WechatSogouAPI.__hosting_wechat_img</td>\n",
       "      <td>def __hosting_wechat_img(self, content_info, h...</td>\n",
       "      <td>[def, __hosting_wechat_img, (, self, ,, conten...</td>\n",
       "      <td>将微信明细中图片托管到云端，同时将html页面中的对应图片替换\\n\\n        Par...</td>\n",
       "      <td>[将微信明细中图片托管到云端，同时将html页面中的对应图片替换]</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10984</th>\n",
       "      <td>WechatSogouAPI.get_article_content</td>\n",
       "      <td>def get_article_content(self, url, del_qqmusic...</td>\n",
       "      <td>[def, get_article_content, (, self, ,, url, ,,...</td>\n",
       "      <td>获取文章原文，避免临时链接失效\\n\\n        Parameters\\n       ...</td>\n",
       "      <td>[获取文章原文，避免临时链接失效]</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10985</th>\n",
       "      <td>WechatSogouAPI.get_sugg</td>\n",
       "      <td>def get_sugg(self, keyword):\\n        \"\"\"获取微信搜...</td>\n",
       "      <td>[def, get_sugg, (, self, ,, keyword, ), :, url...</td>\n",
       "      <td>获取微信搜狗搜索关键词联想\\n\\n        Parameters\\n        -...</td>\n",
       "      <td>[获取微信搜狗搜索关键词联想]</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10986</th>\n",
       "      <td>unlock_sogou_callback_example</td>\n",
       "      <td>def unlock_sogou_callback_example(url, req, re...</td>\n",
       "      <td>[def, unlock_sogou_callback_example, (, url, ,...</td>\n",
       "      <td>手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...</td>\n",
       "      <td>[手动打码解锁]</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10987</th>\n",
       "      <td>unlock_weixin_callback_example</td>\n",
       "      <td>def unlock_weixin_callback_example(url, req, r...</td>\n",
       "      <td>[def, unlock_weixin_callback_example, (, url, ...</td>\n",
       "      <td>手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...</td>\n",
       "      <td>[手动打码解锁]</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 func_name  \\\n",
       "10978  WechatSogouAPI.__hosting_wechat_img   \n",
       "10984   WechatSogouAPI.get_article_content   \n",
       "10985              WechatSogouAPI.get_sugg   \n",
       "10986        unlock_sogou_callback_example   \n",
       "10987       unlock_weixin_callback_example   \n",
       "\n",
       "                                        func_code_string  \\\n",
       "10978  def __hosting_wechat_img(self, content_info, h...   \n",
       "10984  def get_article_content(self, url, del_qqmusic...   \n",
       "10985  def get_sugg(self, keyword):\\n        \"\"\"获取微信搜...   \n",
       "10986  def unlock_sogou_callback_example(url, req, re...   \n",
       "10987  def unlock_weixin_callback_example(url, req, r...   \n",
       "\n",
       "                                        func_code_tokens  \\\n",
       "10978  [def, __hosting_wechat_img, (, self, ,, conten...   \n",
       "10984  [def, get_article_content, (, self, ,, url, ,,...   \n",
       "10985  [def, get_sugg, (, self, ,, keyword, ), :, url...   \n",
       "10986  [def, unlock_sogou_callback_example, (, url, ,...   \n",
       "10987  [def, unlock_weixin_callback_example, (, url, ...   \n",
       "\n",
       "                               func_documentation_string  \\\n",
       "10978  将微信明细中图片托管到云端，同时将html页面中的对应图片替换\\n\\n        Par...   \n",
       "10984  获取文章原文，避免临时链接失效\\n\\n        Parameters\\n       ...   \n",
       "10985  获取微信搜狗搜索关键词联想\\n\\n        Parameters\\n        -...   \n",
       "10986  手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...   \n",
       "10987  手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...   \n",
       "\n",
       "               func_documentation_tokens  func_code_tokens_len  \\\n",
       "10978  [将微信明细中图片托管到云端，同时将html页面中的对应图片替换]                    83   \n",
       "10984                  [获取文章原文，避免临时链接失效]                   116   \n",
       "10985                    [获取微信搜狗搜索关键词联想]                    71   \n",
       "10986                           [手动打码解锁]                   112   \n",
       "10987                           [手动打码解锁]                    97   \n",
       "\n",
       "       func_documentation_tokens_len  \n",
       "10978                              1  \n",
       "10984                              1  \n",
       "10985                              1  \n",
       "10986                              1  \n",
       "10987                              1  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the length of code token and docstring token\n",
    "df['func_code_tokens_len'] = df['func_code_tokens'].apply(lambda x: len(x))\n",
    "df['func_documentation_tokens_len'] = df['func_documentation_tokens'].apply(lambda x: len(x))\n",
    "\n",
    "df['func_code_tokens_len'].describe(), df['func_documentation_tokens_len'].describe()\n",
    "\n",
    "# There are chinese documentation...\n",
    "df.loc[df['func_documentation_tokens_len'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf624599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    406508.000000\n",
       " mean        117.024460\n",
       " std         169.413479\n",
       " min          19.000000\n",
       " 25%          43.000000\n",
       " 50%          72.000000\n",
       " 75%         132.000000\n",
       " max       28410.000000\n",
       " Name: func_code_tokens_len, dtype: float64,\n",
       " count    406508.000000\n",
       " mean         16.466761\n",
       " std          23.899018\n",
       " min           1.000000\n",
       " 25%           7.000000\n",
       " 50%          10.000000\n",
       " 75%          17.000000\n",
       " max        1971.000000\n",
       " Name: func_documentation_tokens_len, dtype: float64,\n",
       " 406508,\n",
       " 34518)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_english(s: str) -> bool:\n",
    "    return s.isascii()\n",
    "\n",
    "english_df = df.loc[df['func_documentation_string'].apply(is_english) == True]\n",
    "\n",
    "english_df['func_code_tokens_len'].describe(), english_df['func_documentation_tokens_len'].describe(), len(english_df), len(english_df.loc[df['func_documentation_tokens_len'] < 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e594d2e0",
   "metadata": {},
   "source": [
    "Filter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "faf67ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 406508\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 22014\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 22656\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_dataset(ds, min_doc_token: int, min_code_token: int=0, language='python') -> bool:\n",
    "    # Step 1: Only allow python\n",
    "    if ds['language'] != language:\n",
    "        return False\n",
    "    \n",
    "    # Step 2: Check if the coden token length if > min_code_token\n",
    "    if len(ds['func_code_tokens']) < min_code_token:\n",
    "        return False\n",
    "    \n",
    "    if len(ds['func_documentation_tokens']) < min_doc_token:\n",
    "        return False\n",
    "    \n",
    "    # Step 3: Check if the func documentation only include ascii code (exclude non-english).\n",
    "    if ds['func_documentation_string'].isascii() == False:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "ds.filter(lambda ds: filter_dataset(ds, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "60ba2e07",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'func_documentation_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m column_to_save = [\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfunc_code_tokens\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfunc_documentation_tokens\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m ]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_to_save\u001b[49m\u001b[43m]\u001b[49m.to_dict()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\howar\\OneDrive\\桌面\\Code\\Git\\Code_Semantic_Search\\.venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:2777\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   2775\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[32m   2776\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2777\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\howar\\OneDrive\\桌面\\Code\\Git\\Code_Semantic_Search\\.venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:2761\u001b[39m, in \u001b[36mDataset._getitem\u001b[39m\u001b[34m(self, key, **kwargs)\u001b[39m\n\u001b[32m   2759\u001b[39m format_kwargs = format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m   2760\u001b[39m formatter = get_formatter(format_type, features=\u001b[38;5;28mself\u001b[39m._info.features, **format_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m2761\u001b[39m pa_subtable = \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2762\u001b[39m formatted_output = format_table(\n\u001b[32m   2763\u001b[39m     pa_subtable, key, formatter=formatter, format_columns=format_columns, output_all_columns=output_all_columns\n\u001b[32m   2764\u001b[39m )\n\u001b[32m   2765\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\howar\\OneDrive\\桌面\\Code\\Git\\Code_Semantic_Search\\.venv\\Lib\\site-packages\\datasets\\formatting\\formatting.py:607\u001b[39m, in \u001b[36mquery_table\u001b[39m\u001b[34m(table, key, indices)\u001b[39m\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    606\u001b[39m     size = indices.num_rows \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m table.num_rows\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m     \u001b[43m_check_valid_index_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[38;5;66;03m# Query the main table\u001b[39;00m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\howar\\OneDrive\\桌面\\Code\\Git\\Code_Semantic_Search\\.venv\\Lib\\site-packages\\datasets\\formatting\\formatting.py:557\u001b[39m, in \u001b[36m_check_valid_index_key\u001b[39m\u001b[34m(key, size)\u001b[39m\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Iterable):\n\u001b[32m    556\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m         _check_valid_index_key(\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, size=size)\n\u001b[32m    558\u001b[39m         _check_valid_index_key(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(key)), size=size)\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: 'func_documentation_tokens'"
     ]
    }
   ],
   "source": [
    "column_to_save = [\n",
    "    'func_code_tokens',\n",
    "    'func_documentation_tokens'\n",
    "]\n",
    "\n",
    "ds['train'][column_to_save].to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
