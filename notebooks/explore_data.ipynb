{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb1772d",
   "metadata": {},
   "source": [
    "Analysis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b871de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\Code_Semantic_Search\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9576b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and convert to dataframe\n",
    "ds = load_dataset(\"code_search_net\", \"python\", trust_remote_code=True)\n",
    "df = ds['train'].to_pandas()\n",
    "\n",
    "# Retrieve necessary data series.\n",
    "df = df[['func_name', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d07345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 412178, 'test': 22176, 'validation': 23107}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of data in each set\n",
    "ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30bef545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>func_name</th>\n",
       "      <th>func_code_string</th>\n",
       "      <th>func_code_tokens</th>\n",
       "      <th>func_documentation_string</th>\n",
       "      <th>func_documentation_tokens</th>\n",
       "      <th>func_code_tokens_len</th>\n",
       "      <th>func_documentation_tokens_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>WechatSogouAPI.__hosting_wechat_img</td>\n",
       "      <td>def __hosting_wechat_img(self, content_info, h...</td>\n",
       "      <td>[def, __hosting_wechat_img, (, self, ,, conten...</td>\n",
       "      <td>将微信明细中图片托管到云端，同时将html页面中的对应图片替换\\n\\n        Par...</td>\n",
       "      <td>[将微信明细中图片托管到云端，同时将html页面中的对应图片替换]</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10984</th>\n",
       "      <td>WechatSogouAPI.get_article_content</td>\n",
       "      <td>def get_article_content(self, url, del_qqmusic...</td>\n",
       "      <td>[def, get_article_content, (, self, ,, url, ,,...</td>\n",
       "      <td>获取文章原文，避免临时链接失效\\n\\n        Parameters\\n       ...</td>\n",
       "      <td>[获取文章原文，避免临时链接失效]</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10985</th>\n",
       "      <td>WechatSogouAPI.get_sugg</td>\n",
       "      <td>def get_sugg(self, keyword):\\n        \"\"\"获取微信搜...</td>\n",
       "      <td>[def, get_sugg, (, self, ,, keyword, ), :, url...</td>\n",
       "      <td>获取微信搜狗搜索关键词联想\\n\\n        Parameters\\n        -...</td>\n",
       "      <td>[获取微信搜狗搜索关键词联想]</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10986</th>\n",
       "      <td>unlock_sogou_callback_example</td>\n",
       "      <td>def unlock_sogou_callback_example(url, req, re...</td>\n",
       "      <td>[def, unlock_sogou_callback_example, (, url, ,...</td>\n",
       "      <td>手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...</td>\n",
       "      <td>[手动打码解锁]</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10987</th>\n",
       "      <td>unlock_weixin_callback_example</td>\n",
       "      <td>def unlock_weixin_callback_example(url, req, r...</td>\n",
       "      <td>[def, unlock_weixin_callback_example, (, url, ...</td>\n",
       "      <td>手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...</td>\n",
       "      <td>[手动打码解锁]</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 func_name  \\\n",
       "10978  WechatSogouAPI.__hosting_wechat_img   \n",
       "10984   WechatSogouAPI.get_article_content   \n",
       "10985              WechatSogouAPI.get_sugg   \n",
       "10986        unlock_sogou_callback_example   \n",
       "10987       unlock_weixin_callback_example   \n",
       "\n",
       "                                        func_code_string  \\\n",
       "10978  def __hosting_wechat_img(self, content_info, h...   \n",
       "10984  def get_article_content(self, url, del_qqmusic...   \n",
       "10985  def get_sugg(self, keyword):\\n        \"\"\"获取微信搜...   \n",
       "10986  def unlock_sogou_callback_example(url, req, re...   \n",
       "10987  def unlock_weixin_callback_example(url, req, r...   \n",
       "\n",
       "                                        func_code_tokens  \\\n",
       "10978  [def, __hosting_wechat_img, (, self, ,, conten...   \n",
       "10984  [def, get_article_content, (, self, ,, url, ,,...   \n",
       "10985  [def, get_sugg, (, self, ,, keyword, ), :, url...   \n",
       "10986  [def, unlock_sogou_callback_example, (, url, ,...   \n",
       "10987  [def, unlock_weixin_callback_example, (, url, ...   \n",
       "\n",
       "                               func_documentation_string  \\\n",
       "10978  将微信明细中图片托管到云端，同时将html页面中的对应图片替换\\n\\n        Par...   \n",
       "10984  获取文章原文，避免临时链接失效\\n\\n        Parameters\\n       ...   \n",
       "10985  获取微信搜狗搜索关键词联想\\n\\n        Parameters\\n        -...   \n",
       "10986  手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...   \n",
       "10987  手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...   \n",
       "\n",
       "               func_documentation_tokens  func_code_tokens_len  \\\n",
       "10978  [将微信明细中图片托管到云端，同时将html页面中的对应图片替换]                    83   \n",
       "10984                  [获取文章原文，避免临时链接失效]                   116   \n",
       "10985                    [获取微信搜狗搜索关键词联想]                    71   \n",
       "10986                           [手动打码解锁]                   112   \n",
       "10987                           [手动打码解锁]                    97   \n",
       "\n",
       "       func_documentation_tokens_len  \n",
       "10978                              1  \n",
       "10984                              1  \n",
       "10985                              1  \n",
       "10986                              1  \n",
       "10987                              1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the length of code token and docstring token\n",
    "df['func_code_tokens_len'] = df['func_code_tokens'].apply(lambda x: len(x))\n",
    "df['func_documentation_tokens_len'] = df['func_documentation_tokens'].apply(lambda x: len(x))\n",
    "\n",
    "df['func_code_tokens_len'].describe(), df['func_documentation_tokens_len'].describe()\n",
    "\n",
    "# There are chinese documentation...\n",
    "df.loc[df['func_documentation_tokens_len'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5917652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_dataset(ds, min_doc_token: int, max_doc_token: int, min_code_token: int, max_code_token: int, language='python') -> bool:\n",
    "    # Step 1: Only allow python\n",
    "    if ds['language'] != language:\n",
    "        return False\n",
    "    \n",
    "    # Step 2: Check if the coden token length if > min_code_token\n",
    "    if len(ds['func_code_tokens']) < min_code_token or \\\n",
    "        len(ds['func_code_tokens']) > max_code_token:\n",
    "        return False\n",
    "    \n",
    "    if len(ds['func_documentation_tokens']) < min_doc_token or \\\n",
    "        len(ds['func_documentation_tokens']) > max_doc_token:\n",
    "        return False\n",
    "    \n",
    "    # Step 3: Check if the func documentation only include ascii code (exclude non-english).\n",
    "    if ds['func_documentation_string'].isascii() == False:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def _filter_columns_from_dataset(datasets, columns_to_save: list):\n",
    "\n",
    "    # Get all the columns names\n",
    "    dataset_columns_to_remove = {\n",
    "        dataset: columns for dataset, columns in datasets.column_names.items()\n",
    "    }\n",
    "\n",
    "    # Remove columns to save from all the column names\n",
    "    for dataset in dataset_columns_to_remove:\n",
    "        for column in columns_to_save:\n",
    "            if column in dataset_columns_to_remove[dataset]:\n",
    "                dataset_columns_to_remove[dataset].remove(column)\n",
    "\n",
    "    # Remove all the columns except columns_to_save.\n",
    "    for dataset in datasets:\n",
    "        datasets[dataset] = datasets[dataset].remove_columns(dataset_columns_to_remove[dataset])\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "columns_to_save = [\n",
    "        'func_code_string',\n",
    "        'func_code_tokens',\n",
    "        'func_documentation_string',\n",
    "        'func_documentation_tokens'\n",
    "    ]\n",
    "\n",
    "filtered_ds = ds.filter(lambda example: _filter_dataset(example, 0, 64, 0, 64))\n",
    "filtered_ds = _filter_columns_from_dataset(ds, columns_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02ad6225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 412178/412178 [00:37<00:00, 11085.98 examples/s]\n",
      "Map: 100%|██████████| 22176/22176 [00:02<00:00, 10623.71 examples/s]\n",
      "Map: 100%|██████████| 23107/23107 [00:02<00:00, 10287.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def _unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def _normalize_string(s):\n",
    "    s = _unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "def preprocess_documentation_string_to_tokens(s):\n",
    "    return _normalize_string(s).split()\n",
    "\n",
    "filtered_ds = filtered_ds.map(\n",
    "    lambda example: {\n",
    "        'func_documentation_tokens': preprocess_documentation_string_to_tokens(example['func_documentation_string'])\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f43d459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>func_code_string</th>\n",
       "      <th>func_code_tokens</th>\n",
       "      <th>func_documentation_string</th>\n",
       "      <th>func_documentation_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def train(train_dir, model_save_path=None, n_n...</td>\n",
       "      <td>[def, train, (, train_dir, ,, model_save_path,...</td>\n",
       "      <td>Trains a k-nearest neighbors classifier for fa...</td>\n",
       "      <td>[trains, a, k, nearest, neighbors, classifier,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n",
       "      <td>[def, predict, (, X_img_path, ,, knn_clf, =, N...</td>\n",
       "      <td>Recognizes faces in given image using a traine...</td>\n",
       "      <td>[recognizes, faces, in, given, image, using, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def show_prediction_labels_on_image(img_path, ...</td>\n",
       "      <td>[def, show_prediction_labels_on_image, (, img_...</td>\n",
       "      <td>Shows the face recognition results visually.\\n...</td>\n",
       "      <td>[shows, the, face, recognition, results, visua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n",
       "      <td>[def, _rect_to_css, (, rect, ), :, return, rec...</td>\n",
       "      <td>Convert a dlib 'rect' object to a plain tuple ...</td>\n",
       "      <td>[convert, a, dlib, rect, object, to, a, plain,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n",
       "      <td>[def, _trim_css_to_bounds, (, css, ,, image_sh...</td>\n",
       "      <td>Make sure a tuple in (top, right, bottom, left...</td>\n",
       "      <td>[make, sure, a, tuple, in, top, right, bottom,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    func_code_string  \\\n",
       "0  def train(train_dir, model_save_path=None, n_n...   \n",
       "1  def predict(X_img_path, knn_clf=None, model_pa...   \n",
       "2  def show_prediction_labels_on_image(img_path, ...   \n",
       "3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n",
       "4  def _trim_css_to_bounds(css, image_shape):\\n  ...   \n",
       "\n",
       "                                    func_code_tokens  \\\n",
       "0  [def, train, (, train_dir, ,, model_save_path,...   \n",
       "1  [def, predict, (, X_img_path, ,, knn_clf, =, N...   \n",
       "2  [def, show_prediction_labels_on_image, (, img_...   \n",
       "3  [def, _rect_to_css, (, rect, ), :, return, rec...   \n",
       "4  [def, _trim_css_to_bounds, (, css, ,, image_sh...   \n",
       "\n",
       "                           func_documentation_string  \\\n",
       "0  Trains a k-nearest neighbors classifier for fa...   \n",
       "1  Recognizes faces in given image using a traine...   \n",
       "2  Shows the face recognition results visually.\\n...   \n",
       "3  Convert a dlib 'rect' object to a plain tuple ...   \n",
       "4  Make sure a tuple in (top, right, bottom, left...   \n",
       "\n",
       "                           func_documentation_tokens  \n",
       "0  [trains, a, k, nearest, neighbors, classifier,...  \n",
       "1  [recognizes, faces, in, given, image, using, a...  \n",
       "2  [shows, the, face, recognition, results, visua...  \n",
       "3  [convert, a, dlib, rect, object, to, a, plain,...  \n",
       "4  [make, sure, a, tuple, in, top, right, bottom,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_pd = filtered_ds['train'].to_pandas()\n",
    "filtered_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de18fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code tokens: 8192\n",
      "doc tokens: 8192\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Code\\Code_Semantic_Search')\n",
    "\n",
    "from data.tokenizer import Tokenizer\n",
    "code_tokenizer = Tokenizer(8192)\n",
    "doc_tokenizer = Tokenizer(8192)\n",
    "\n",
    "# Load tokens in tokenizer\n",
    "code_tokenizer.load_datasets(filtered_ds, 'func_code_tokens')\n",
    "doc_tokenizer.load_datasets(filtered_ds, 'func_documentation_tokens')\n",
    "print(f'code tokens: {len(code_tokenizer)}')\n",
    "print(f'doc tokens: {len(doc_tokenizer)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "532179d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 412178/412178 [00:51<00:00, 8005.37 examples/s]\n",
      "Filter: 100%|██████████| 22176/22176 [00:02<00:00, 8164.58 examples/s]\n",
      "Filter: 100%|██████████| 23107/23107 [00:03<00:00, 7561.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# filter the dataset to only include allow code tokens and allow documentation tokens\n",
    "# so that the dataset will not have any unknown token\n",
    "def _filter_tokens(ds, allow_code_tokens, allow_doc_tokens) -> bool:\n",
    "    for code_token, doc_token in zip(ds['func_code_tokens'], ds['func_documentation_tokens']):\n",
    "        if code_token not in allow_code_tokens:\n",
    "            return False\n",
    "\n",
    "        if doc_token not in allow_doc_tokens:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "filtered_tokens = filtered_ds.filter(lambda example: _filter_tokens(example, code_tokenizer.most_freq_tokens, doc_tokenizer.most_freq_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a08acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37671, 2049, 2401)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_tokens['train']), len(filtered_tokens['test']), len(filtered_tokens['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0aa461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
