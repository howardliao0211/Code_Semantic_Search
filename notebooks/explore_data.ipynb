{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb1772d",
   "metadata": {},
   "source": [
    "Analysis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b871de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b9576b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>func_name</th>\n",
       "      <th>func_code_string</th>\n",
       "      <th>func_code_tokens</th>\n",
       "      <th>func_documentation_string</th>\n",
       "      <th>func_documentation_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>def train(train_dir, model_save_path=None, n_n...</td>\n",
       "      <td>[def, train, (, train_dir, ,, model_save_path,...</td>\n",
       "      <td>Trains a k-nearest neighbors classifier for fa...</td>\n",
       "      <td>[Trains, a, k, -, nearest, neighbors, classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>predict</td>\n",
       "      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n",
       "      <td>[def, predict, (, X_img_path, ,, knn_clf, =, N...</td>\n",
       "      <td>Recognizes faces in given image using a traine...</td>\n",
       "      <td>[Recognizes, faces, in, given, image, using, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>show_prediction_labels_on_image</td>\n",
       "      <td>def show_prediction_labels_on_image(img_path, ...</td>\n",
       "      <td>[def, show_prediction_labels_on_image, (, img_...</td>\n",
       "      <td>Shows the face recognition results visually.\\n...</td>\n",
       "      <td>[Shows, the, face, recognition, results, visua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_rect_to_css</td>\n",
       "      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n",
       "      <td>[def, _rect_to_css, (, rect, ), :, return, rec...</td>\n",
       "      <td>Convert a dlib 'rect' object to a plain tuple ...</td>\n",
       "      <td>[Convert, a, dlib, rect, object, to, a, plain,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_trim_css_to_bounds</td>\n",
       "      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n",
       "      <td>[def, _trim_css_to_bounds, (, css, ,, image_sh...</td>\n",
       "      <td>Make sure a tuple in (top, right, bottom, left...</td>\n",
       "      <td>[Make, sure, a, tuple, in, (, top, right, bott...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         func_name  \\\n",
       "0                            train   \n",
       "1                          predict   \n",
       "2  show_prediction_labels_on_image   \n",
       "3                     _rect_to_css   \n",
       "4              _trim_css_to_bounds   \n",
       "\n",
       "                                    func_code_string  \\\n",
       "0  def train(train_dir, model_save_path=None, n_n...   \n",
       "1  def predict(X_img_path, knn_clf=None, model_pa...   \n",
       "2  def show_prediction_labels_on_image(img_path, ...   \n",
       "3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n",
       "4  def _trim_css_to_bounds(css, image_shape):\\n  ...   \n",
       "\n",
       "                                    func_code_tokens  \\\n",
       "0  [def, train, (, train_dir, ,, model_save_path,...   \n",
       "1  [def, predict, (, X_img_path, ,, knn_clf, =, N...   \n",
       "2  [def, show_prediction_labels_on_image, (, img_...   \n",
       "3  [def, _rect_to_css, (, rect, ), :, return, rec...   \n",
       "4  [def, _trim_css_to_bounds, (, css, ,, image_sh...   \n",
       "\n",
       "                           func_documentation_string  \\\n",
       "0  Trains a k-nearest neighbors classifier for fa...   \n",
       "1  Recognizes faces in given image using a traine...   \n",
       "2  Shows the face recognition results visually.\\n...   \n",
       "3  Convert a dlib 'rect' object to a plain tuple ...   \n",
       "4  Make sure a tuple in (top, right, bottom, left...   \n",
       "\n",
       "                           func_documentation_tokens  \n",
       "0  [Trains, a, k, -, nearest, neighbors, classifi...  \n",
       "1  [Recognizes, faces, in, given, image, using, a...  \n",
       "2  [Shows, the, face, recognition, results, visua...  \n",
       "3  [Convert, a, dlib, rect, object, to, a, plain,...  \n",
       "4  [Make, sure, a, tuple, in, (, top, right, bott...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset and convert to dataframe\n",
    "ds = load_dataset(\"code_search_net\", \"python\", trust_remote_code=True)\n",
    "df = ds['train'].to_pandas()\n",
    "\n",
    "# Retrieve necessary data series.\n",
    "df = df[['func_name', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'language']]\n",
    "\n",
    "# Only retrieve code written in Python.\n",
    "df = df.loc[df['language'] == 'python'].drop('language', axis=1)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d07345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 412178, 'test': 22176, 'validation': 23107}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of data in each set\n",
    "ds.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30bef545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>func_name</th>\n",
       "      <th>func_code_string</th>\n",
       "      <th>func_code_tokens</th>\n",
       "      <th>func_documentation_string</th>\n",
       "      <th>func_documentation_tokens</th>\n",
       "      <th>func_code_tokens_len</th>\n",
       "      <th>func_documentation_tokens_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>WechatSogouAPI.__hosting_wechat_img</td>\n",
       "      <td>def __hosting_wechat_img(self, content_info, h...</td>\n",
       "      <td>[def, __hosting_wechat_img, (, self, ,, conten...</td>\n",
       "      <td>将微信明细中图片托管到云端，同时将html页面中的对应图片替换\\n\\n        Par...</td>\n",
       "      <td>[将微信明细中图片托管到云端，同时将html页面中的对应图片替换]</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10984</th>\n",
       "      <td>WechatSogouAPI.get_article_content</td>\n",
       "      <td>def get_article_content(self, url, del_qqmusic...</td>\n",
       "      <td>[def, get_article_content, (, self, ,, url, ,,...</td>\n",
       "      <td>获取文章原文，避免临时链接失效\\n\\n        Parameters\\n       ...</td>\n",
       "      <td>[获取文章原文，避免临时链接失效]</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10985</th>\n",
       "      <td>WechatSogouAPI.get_sugg</td>\n",
       "      <td>def get_sugg(self, keyword):\\n        \"\"\"获取微信搜...</td>\n",
       "      <td>[def, get_sugg, (, self, ,, keyword, ), :, url...</td>\n",
       "      <td>获取微信搜狗搜索关键词联想\\n\\n        Parameters\\n        -...</td>\n",
       "      <td>[获取微信搜狗搜索关键词联想]</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10986</th>\n",
       "      <td>unlock_sogou_callback_example</td>\n",
       "      <td>def unlock_sogou_callback_example(url, req, re...</td>\n",
       "      <td>[def, unlock_sogou_callback_example, (, url, ,...</td>\n",
       "      <td>手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...</td>\n",
       "      <td>[手动打码解锁]</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10987</th>\n",
       "      <td>unlock_weixin_callback_example</td>\n",
       "      <td>def unlock_weixin_callback_example(url, req, r...</td>\n",
       "      <td>[def, unlock_weixin_callback_example, (, url, ...</td>\n",
       "      <td>手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...</td>\n",
       "      <td>[手动打码解锁]</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 func_name  \\\n",
       "10978  WechatSogouAPI.__hosting_wechat_img   \n",
       "10984   WechatSogouAPI.get_article_content   \n",
       "10985              WechatSogouAPI.get_sugg   \n",
       "10986        unlock_sogou_callback_example   \n",
       "10987       unlock_weixin_callback_example   \n",
       "\n",
       "                                        func_code_string  \\\n",
       "10978  def __hosting_wechat_img(self, content_info, h...   \n",
       "10984  def get_article_content(self, url, del_qqmusic...   \n",
       "10985  def get_sugg(self, keyword):\\n        \"\"\"获取微信搜...   \n",
       "10986  def unlock_sogou_callback_example(url, req, re...   \n",
       "10987  def unlock_weixin_callback_example(url, req, r...   \n",
       "\n",
       "                                        func_code_tokens  \\\n",
       "10978  [def, __hosting_wechat_img, (, self, ,, conten...   \n",
       "10984  [def, get_article_content, (, self, ,, url, ,,...   \n",
       "10985  [def, get_sugg, (, self, ,, keyword, ), :, url...   \n",
       "10986  [def, unlock_sogou_callback_example, (, url, ,...   \n",
       "10987  [def, unlock_weixin_callback_example, (, url, ...   \n",
       "\n",
       "                               func_documentation_string  \\\n",
       "10978  将微信明细中图片托管到云端，同时将html页面中的对应图片替换\\n\\n        Par...   \n",
       "10984  获取文章原文，避免临时链接失效\\n\\n        Parameters\\n       ...   \n",
       "10985  获取微信搜狗搜索关键词联想\\n\\n        Parameters\\n        -...   \n",
       "10986  手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...   \n",
       "10987  手动打码解锁\\n\\n    Parameters\\n    ----------\\n    ...   \n",
       "\n",
       "               func_documentation_tokens  func_code_tokens_len  \\\n",
       "10978  [将微信明细中图片托管到云端，同时将html页面中的对应图片替换]                    83   \n",
       "10984                  [获取文章原文，避免临时链接失效]                   116   \n",
       "10985                    [获取微信搜狗搜索关键词联想]                    71   \n",
       "10986                           [手动打码解锁]                   112   \n",
       "10987                           [手动打码解锁]                    97   \n",
       "\n",
       "       func_documentation_tokens_len  \n",
       "10978                              1  \n",
       "10984                              1  \n",
       "10985                              1  \n",
       "10986                              1  \n",
       "10987                              1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the length of code token and docstring token\n",
    "df['func_code_tokens_len'] = df['func_code_tokens'].apply(lambda x: len(x))\n",
    "df['func_documentation_tokens_len'] = df['func_documentation_tokens'].apply(lambda x: len(x))\n",
    "\n",
    "df['func_code_tokens_len'].describe(), df['func_documentation_tokens_len'].describe()\n",
    "\n",
    "# There are chinese documentation...\n",
    "df.loc[df['func_documentation_tokens_len'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf624599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count    406508.000000\n",
       " mean        117.024460\n",
       " std         169.413479\n",
       " min          19.000000\n",
       " 25%          43.000000\n",
       " 50%          72.000000\n",
       " 75%         132.000000\n",
       " max       28410.000000\n",
       " Name: func_code_tokens_len, dtype: float64,\n",
       " count    406508.000000\n",
       " mean         16.466761\n",
       " std          23.899018\n",
       " min           1.000000\n",
       " 25%           7.000000\n",
       " 50%          10.000000\n",
       " 75%          17.000000\n",
       " max        1971.000000\n",
       " Name: func_documentation_tokens_len, dtype: float64,\n",
       " 406508,\n",
       " 34518)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_english(s: str) -> bool:\n",
    "    return s.isascii()\n",
    "\n",
    "english_df = df.loc[df['func_documentation_string'].apply(is_english) == True]\n",
    "\n",
    "english_df['func_code_tokens_len'].describe(), english_df['func_documentation_tokens_len'].describe(), len(english_df), len(english_df.loc[df['func_documentation_tokens_len'] < 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e594d2e0",
   "metadata": {},
   "source": [
    "Filter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "faf67ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 412178/412178 [00:54<00:00, 7509.31 examples/s]\n",
      "Filter: 100%|██████████| 22176/22176 [00:02<00:00, 7570.29 examples/s]\n",
      "Filter: 100%|██████████| 23107/23107 [00:03<00:00, 7225.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def _filter_dataset(ds, min_doc_token: int, max_doc_token: int, min_code_token: int, max_code_token: int, language='python') -> bool:\n",
    "    # Step 1: Only allow python\n",
    "    if ds['language'] != language:\n",
    "        return False\n",
    "    \n",
    "    # Step 2: Check if the coden token length if > min_code_token\n",
    "    if len(ds['func_code_tokens']) < min_code_token or \\\n",
    "        len(ds['func_code_tokens']) > max_code_token:\n",
    "        return False\n",
    "    \n",
    "    if len(ds['func_documentation_tokens']) < min_doc_token or \\\n",
    "        len(ds['func_documentation_tokens']) > max_doc_token:\n",
    "        return False\n",
    "    \n",
    "    # Step 3: Check if the func documentation only include ascii code (exclude non-english).\n",
    "    if ds['func_documentation_string'].isascii() == False:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "ds = ds.filter(lambda ds: _filter_dataset(\n",
    "        ds=ds,\n",
    "        min_doc_token=0,\n",
    "        max_doc_token=256,\n",
    "        min_code_token=0,\n",
    "        max_code_token=256\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a2e6dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    371335.000000\n",
       "mean         15.610705\n",
       "std          17.268367\n",
       "min           1.000000\n",
       "25%           7.000000\n",
       "50%          10.000000\n",
       "75%          17.000000\n",
       "max         256.000000\n",
       "Name: func_documentation_tokens_len, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds['train'].to_pandas()\n",
    "df['func_documentation_tokens_len'] = df['func_documentation_tokens'].apply(len)\n",
    "df['func_documentation_tokens_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60ba2e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['func_code_tokens', 'func_documentation_tokens'],\n",
       "         num_rows: 371335\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['func_code_tokens', 'func_documentation_tokens'],\n",
       "         num_rows: 20184\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['func_code_tokens', 'func_documentation_tokens'],\n",
       "         num_rows: 20458\n",
       "     })\n",
       " }),\n",
       " ['def',\n",
       "  'predict',\n",
       "  '(',\n",
       "  'X_img_path',\n",
       "  ',',\n",
       "  'knn_clf',\n",
       "  '=',\n",
       "  'None',\n",
       "  ',',\n",
       "  'model_path'],\n",
       " ['Recognizes',\n",
       "  'faces',\n",
       "  'in',\n",
       "  'given',\n",
       "  'image',\n",
       "  'using',\n",
       "  'a',\n",
       "  'trained',\n",
       "  'KNN',\n",
       "  'classifier'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _filter_column_from_dataset(datasets, column_to_save: list):\n",
    "\n",
    "    dataset_columns_to_remove = {\n",
    "        dataset: columns for dataset, columns in datasets.column_names.items()\n",
    "    }\n",
    "\n",
    "    for dataset in dataset_columns_to_remove:\n",
    "        for column in column_to_save:\n",
    "            if column in dataset_columns_to_remove[dataset]:\n",
    "                dataset_columns_to_remove[dataset].remove(column)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        datasets[dataset] = datasets[dataset].remove_columns(dataset_columns_to_remove[dataset])\n",
    "\n",
    "column_to_save = [\n",
    "        'func_code_tokens',\n",
    "        'func_documentation_tokens'\n",
    "    ]\n",
    "\n",
    "_filter_column_from_dataset(ds, column_to_save)\n",
    "ds, ds['train'][0]['func_code_tokens'][:10], ds['train'][0]['func_documentation_tokens'][:30], \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e009c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 371335/371335 [01:09<00:00, 5365.70 examples/s]\n",
      "Map: 100%|██████████| 20184/20184 [00:03<00:00, 5401.78 examples/s]\n",
      "Map: 100%|██████████| 20458/20458 [00:03<00:00, 5388.84 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Code\\Code_Semantic_Search\\data')\n",
    "\n",
    "from tokenizer import Tokenizer\n",
    "\n",
    "def _tokenize(example, tokenizer: Tokenizer) -> int:\n",
    "    return {\n",
    "        'func_code_tokens': tokenizer.to_idx(example['func_code_tokens']),\n",
    "        'func_documentation_tokens': tokenizer.to_idx(example['func_documentation_tokens']),\n",
    "    }\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "ds = ds.map(lambda example: _tokenize(example, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a80a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4,  5,  6,  7,  8,  9, 10, 11,  8, 12, 10, 11,  8, 13, 10, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 20, 22,  6,  7, 15, 23, 19, 20, 21, 20, 24,  6,  7,\n",
       "        15, 25, 26, 27, 25, 26, 16, 27, 18, 28, 29, 16, 30, 31,  6, 32, 20, 33,\n",
       "         6,  7, 15, 15, 17,  9, 34, 11, 35, 12, 34, 11, 16, 30, 31,  6, 36, 15,\n",
       "        37, 17,  9, 34, 11, 16, 38, 39,  6, 12,  8, 40, 15, 41, 42, 16,  9, 10,\n",
       "        43, 20, 44,  6, 42, 15, 45, 46, 10, 47, 20, 48,  6,  7, 15, 49, 10, 47,\n",
       "        20, 50,  6, 46, 15, 51, 17, 52,  6, 49, 15, 53, 54, 16, 55, 25, 27, 56,\n",
       "        57, 10, 47, 20, 58,  6, 46,  8, 59, 10, 49, 15, 60, 61, 10,  9, 20, 62,\n",
       "         6, 57,  8, 63, 10, 26, 15, 64, 10, 25, 61, 25, 54, 27, 25, 65, 27, 25,\n",
       "        54, 27, 66, 13, 67, 65, 28, 68,  6, 52,  6, 49, 15, 15, 27, 69, 55, 25,\n",
       "         6, 70,  8, 71, 15, 17, 72, 73,  6, 74,  8, 71, 15, 67, 70,  8, 71,  8,\n",
       "        72, 28, 75,  6,  9, 20,  5,  6, 57, 15,  8, 49,  8, 64, 15, 27])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_torch = ds.with_format(\"torch\")\n",
    "ds_torch['train'][0]['func_code_tokens']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
